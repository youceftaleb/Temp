{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f4e90b",
   "metadata": {},
   "source": [
    "# TP3 ‚Äì R√©gression Lin√©aire Multivariable sur donn√©es biologiques\n",
    "# Objectif du TP\n",
    "\n",
    "\"\"\"\n",
    "L'objectif de ce TP est de r√©aliser un projet complet de r√©gression lin√©aire multivariable\n",
    "pour pr√©dire des valeurs continues √† partir de donn√©es d'expression g√©nique.\n",
    "\n",
    "Dans ce TP, nous allons :\n",
    "- Utiliser la r√©gression lin√©aire pour pr√©dire une variable continue\n",
    "- Impl√©menter manuellement l'algorithme sans utiliser de biblioth√®ques ML\n",
    "- Calculer les coefficients par la m√©thode des moindres carr√©s\n",
    "- √âvaluer les performances avec R¬≤, MSE, RMSE, MAE\n",
    "\"\"\"\n",
    "\n",
    "# ==============================================================================\n",
    "# PARTIE 1 : PR√âTRAITEMENT DES DONN√âES\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4d36fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aper√ßu du jeu de donn√©es original :\n",
      "                                                                                                            Date;Time;CO(GT);PT08.S1(CO);NMHC(GT);C6H6(GT);PT08.S2(NMHC);NOx(GT);PT08.S3(NOx);NO2(GT);PT08.S4(NO2);PT08.S5(O3);T;RH;AH;;\n",
      "10/03/2004;18.00.00;2            6;1360;150;11                 9;1046;166;1056;113;1692;1268;13 6;48 9;0                                                7578;;                                                                          \n",
      "10/03/2004;19.00.00;2;1292;112;9 4;955;103;1174;92;1559;972;13 3;47                             7;0  7255;;                                                NaN                                                                          \n",
      "10/03/2004;20.00.00;2            2;1402;88;9                   0;939;131;1140;114;1555;1074;11  9;54 0;0                                                7502;;                                                                          \n",
      "10/03/2004;21.00.00;2            2;1376;80;9                   2;948;172;1092;122;1584;1203;11  0;60 0;0                                                7867;;                                                                          \n",
      "10/03/2004;22.00.00;1            6;1272;51;6                   5;836;131;1205;116;1490;1110;11  2;59 6;0                                                7888;;                                                                          \n",
      "\n",
      "Dimensions : 9471 lignes √ó 1 colonnes\n",
      "\n",
      "Valeurs manquantes d√©tect√©es : 2556\n",
      "Valeurs manquantes remplac√©es par la moyenne\n",
      "\n",
      "‚ö†Ô∏è 4529 doublon(s) d√©tect√©(s)\n",
      "Doublons supprim√©s\n",
      "\n",
      "üéØ Cr√©ation de la variable cible pour la r√©gression...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['7578;;' 0 '7502;;' ... '7531;;' '7119;;' '5028;;'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:1688\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m     x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplex128\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[31mValueError\u001b[39m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:1691\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1690\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m     x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1693\u001b[39m     \u001b[38;5;66;03m# GH#29941 we get here with object arrays containing strs\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '7578;;'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# S√©lection des 10 premiers g√®nes pour cr√©er notre variable cible\u001b[39;00m\n\u001b[32m     52\u001b[39m target_genes = df.columns[\u001b[32m0\u001b[39m:\u001b[32m10\u001b[39m].tolist()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtarget_expression\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_genes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVariable cible cr√©√©e : \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtarget_expression\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStatistiques de la variable cible :\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11720\u001b[39m, in \u001b[36mDataFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11712\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n\u001b[32m  11713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  11714\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11718\u001b[39m     **kwargs,\n\u001b[32m  11719\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m11720\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11721\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[32m  11722\u001b[39m         result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12485\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12480\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12483\u001b[39m     **kwargs,\n\u001b[32m  12484\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12486\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12487\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12442\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12438\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12440\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11589\u001b[39m, in \u001b[36mDataFrame._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m  11585\u001b[39m     df = df.T\n\u001b[32m  11587\u001b[39m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[32m  11588\u001b[39m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11589\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11590\u001b[39m out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001b[32m0\u001b[39m]\n\u001b[32m  11591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out.dtype != \u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1519\u001b[39m, in \u001b[36mBlockManager.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1517\u001b[39m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   1518\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m-> \u001b[39m\u001b[32m1519\u001b[39m     nbs = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1520\u001b[39m     res_blocks.extend(nbs)\n\u001b[32m   1522\u001b[39m index = Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:406\u001b[39m, in \u001b[36mBlock.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    409\u001b[39m         res_values = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11508\u001b[39m, in \u001b[36mDataFrame._reduce.<locals>.blk_func\u001b[39m\u001b[34m(values, axis)\u001b[39m\n\u001b[32m  11506\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([result])\n\u001b[32m  11507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m11508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    718\u001b[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    723\u001b[39m     count = cast(np.ndarray, count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:1694\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1691\u001b[39m         x = x.astype(np.float64)\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1693\u001b[39m         \u001b[38;5;66;03m# GH#29941 we get here with object arrays containing strs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.any(np.imag(x)):\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert ['7578;;' 0 '7502;;' ... '7531;;' '7119;;' '5028;;'] to numeric"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cr√©ation du r√©pertoire de travail\n",
    "BASE_DIR = \"/home/youcef/bioinfo/fd\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Chargement du dataset\n",
    "file_path = \"/home/youcef/bioinfo/fd/AirQualityUCI.csv\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Le fichier n'existe pas : {file_path}\")\n",
    "    print(\"Veuillez v√©rifier le chemin d'acc√®s.\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(\"\\nAper√ßu du jeu de donn√©es original :\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nDimensions : {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "    \n",
    "    # V√©rification des valeurs manquantes\n",
    "    missing_counts = df.isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "    \n",
    "    if total_missing > 0:\n",
    "        print(f\"\\nValeurs manquantes d√©tect√©es : {total_missing}\")\n",
    "        # Remplacement par la moyenne\n",
    "        for col in df.select_dtypes(include=[np.number]).columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].mean(), inplace=True)\n",
    "        print(\"Valeurs manquantes remplac√©es par la moyenne\")\n",
    "    else:\n",
    "        print(\"\\nAucune valeur manquante d√©tect√©e\")\n",
    "    \n",
    "    # Suppression des doublons\n",
    "    nb_doublons = df.duplicated().sum()\n",
    "    if nb_doublons > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è {nb_doublons} doublon(s) d√©tect√©(s)\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(\"Doublons supprim√©s\")\n",
    "    else:\n",
    "        print(\"Aucun doublon d√©tect√©\")\n",
    "    \n",
    "    # Pour la r√©gression, nous allons cr√©er une variable cible continue\n",
    "    # Nous allons utiliser la moyenne d'expression des premiers g√®nes comme variable √† pr√©dire\n",
    "    print(\"\\nüéØ Cr√©ation de la variable cible pour la r√©gression...\")\n",
    "    \n",
    "    # S√©lection des 10 premiers g√®nes pour cr√©er notre variable cible\n",
    "    target_genes = df.columns[0:10].tolist()\n",
    "    df['target_expression'] = df[target_genes].mean(axis=1)\n",
    "    \n",
    "    print(f\"Variable cible cr√©√©e : 'target_expression'\")\n",
    "    print(f\"Statistiques de la variable cible :\")\n",
    "    print(df['target_expression'].describe())\n",
    "    \n",
    "    # Normalisation (standardisation Z-score pour la r√©gression)\n",
    "    df_norm = df.copy()\n",
    "    \n",
    "    # On exclut la variable cible et sample_type_id de la normalisation des features\n",
    "    features_to_normalize = [col for col in df.columns \n",
    "                            if col not in ['target_expression', 'sample_type_id'] + target_genes]\n",
    "    \n",
    "    for col in features_to_normalize:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        if std_val != 0:\n",
    "            df_norm[col] = (df[col] - mean_val) / std_val\n",
    "        else:\n",
    "            df_norm[col] = 0.0\n",
    "    \n",
    "    print(\"\\n‚úÖ Standardisation Z-score effectu√©e sur les features\")\n",
    "    print(\"\\nüìä Aper√ßu des donn√©es normalis√©es :\")\n",
    "    print(df_norm.head())\n",
    "    \n",
    "    # Sauvegarde\n",
    "    output_preprocessed = f\"{BASE_DIR}/Liver_RNA_preprocessed_LR.csv\"\n",
    "    df_norm.to_csv(output_preprocessed, index=False)\n",
    "    print(f\"\\nüíæ Donn√©es pr√©trait√©es sauvegard√©es : {output_preprocessed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9458e",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# PARTIE 2 : DIVISION DU JEU DE DONN√âES (80% TRAIN / 20% TEST)\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pr√©paration des donn√©es : on exclut les g√®nes utilis√©s pour cr√©er la cible\n",
    "features_columns = [\n",
    "    col\n",
    "    for col in df_norm.columns\n",
    "    if col not in [\"target_expression\", \"sample_type_id\"] + target_genes\n",
    "]\n",
    "\n",
    "X = df_norm[features_columns]\n",
    "y = df_norm[\"target_expression\"]\n",
    "\n",
    "# S√©paration train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Taille du train set : X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"‚úÖ Taille du test set : X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Sauvegarde des fichiers\n",
    "train_df = X_train.copy()\n",
    "train_df[\"target_expression\"] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df[\"target_expression\"] = y_test\n",
    "\n",
    "train_path = f\"{BASE_DIR}/Liver_RNA_train_LR.csv\"\n",
    "test_path = f\"{BASE_DIR}/Liver_RNA_test_LR.csv\"\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Fichier d'entra√Ænement : {train_path}\")\n",
    "print(f\"üíæ Fichier de test : {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56f3fe",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# PARTIE 3 : IMPL√âMENTATION MANUELLE DE LA R√âGRESSION LIN√âAIRE MULTIVARIABLE\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfdd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    \"\"\"\n",
    "    Impl√©mentation manuelle de la r√©gression lin√©aire multivariable.\n",
    "\n",
    "    Mod√®le : y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô\n",
    "\n",
    "    M√©thode des moindres carr√©s :\n",
    "    Œ≤ = (X^T X)^(-1) X^T y\n",
    "\n",
    "    o√π X est la matrice des features avec une colonne de 1 pour l'intercept\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coefficients = None\n",
    "        self.intercept = None\n",
    "        self.n_features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entra√Ænement du mod√®le par la m√©thode des moindres carr√©s.\n",
    "\n",
    "        Args:\n",
    "            X : matrice des features (n_samples, n_features)\n",
    "            y : vecteur cible (n_samples,)\n",
    "        \"\"\"\n",
    "        # Conversion en arrays numpy\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.n_features = X.shape[1]\n",
    "\n",
    "        # Ajout d'une colonne de 1 pour l'intercept\n",
    "        X_with_intercept = np.column_stack([np.ones(len(X)), X])\n",
    "\n",
    "        # Calcul des coefficients : Œ≤ = (X^T X)^(-1) X^T y\n",
    "        # M√©thode 1 : Inversion de matrice (peut √™tre instable)\n",
    "        # XtX = X_with_intercept.T @ X_with_intercept\n",
    "        # Xty = X_with_intercept.T @ y\n",
    "        # beta = np.linalg.inv(XtX) @ Xty\n",
    "\n",
    "        # M√©thode 2 : R√©solution directe du syst√®me (plus stable)\n",
    "        XtX = X_with_intercept.T @ X_with_intercept\n",
    "        Xty = X_with_intercept.T @ y\n",
    "\n",
    "        # Ajout d'un terme de r√©gularisation pour stabilit√© num√©rique\n",
    "        ridge_penalty = 1e-6\n",
    "        XtX_reg = XtX + ridge_penalty * np.eye(XtX.shape[0])\n",
    "\n",
    "        beta = np.linalg.solve(XtX_reg, Xty)\n",
    "\n",
    "        # S√©paration intercept et coefficients\n",
    "        self.intercept = beta[0]\n",
    "        self.coefficients = beta[1:]\n",
    "\n",
    "        print(f\"\\n‚úÖ Mod√®le entra√Æn√© avec succ√®s !\")\n",
    "        print(f\"   Intercept (Œ≤‚ÇÄ) : {self.intercept:.6f}\")\n",
    "        print(f\"   Nombre de coefficients : {len(self.coefficients)}\")\n",
    "        print(f\"   Exemple de coefficients : {self.coefficients[:5]}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Pr√©diction des valeurs cibles.\n",
    "\n",
    "        Args:\n",
    "            X : matrice des features\n",
    "\n",
    "        Returns:\n",
    "            Pr√©dictions (array)\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        return self.intercept + X @ self.coefficients\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        \"\"\"Retourne les coefficients du mod√®le\"\"\"\n",
    "        return {\"intercept\": self.intercept, \"coefficients\": self.coefficients}\n",
    "\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "print(\"\\nüîß Entra√Ænement du mod√®le de r√©gression lin√©aire multivariable...\")\n",
    "lr_model = MultipleLinearRegression()\n",
    "lr_model.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3e9bc",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# PARTIE 4 : √âVALUATION SUR LE JEU D'ENTRA√éNEMENT\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcul manuel des m√©triques de r√©gression.\n",
    "\n",
    "    M√©triques calcul√©es :\n",
    "    - MSE (Mean Squared Error) : moyenne des erreurs au carr√©\n",
    "    - RMSE (Root Mean Squared Error) : racine du MSE\n",
    "    - MAE (Mean Absolute Error) : moyenne des erreurs absolues\n",
    "    - R¬≤ (Coefficient de d√©termination) : proportion de variance expliqu√©e\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Erreurs\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors**2\n",
    "    absolute_errors = np.abs(errors)\n",
    "\n",
    "    # MSE\n",
    "    mse = np.mean(squared_errors)\n",
    "\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # MAE\n",
    "    mae = np.mean(absolute_errors)\n",
    "\n",
    "    # R¬≤ = 1 - (SS_res / SS_tot)\n",
    "    ss_res = np.sum(squared_errors)  # Somme des carr√©s r√©siduels\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # Somme totale des carr√©s\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "\n",
    "    # R¬≤ ajust√© (prend en compte le nombre de features)\n",
    "    # Pas calcul√© ici car n√©cessite le nombre de features\n",
    "\n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"n_samples\": n}\n",
    "\n",
    "\n",
    "# Pr√©dictions sur le train set\n",
    "y_train_pred = lr_model.predict(X_train.values)\n",
    "\n",
    "# Calcul des m√©triques\n",
    "metrics_train = calculate_regression_metrics(y_train.values, y_train_pred)\n",
    "\n",
    "print(\"\\nüìä R√âSULTATS SUR LE TRAIN SET :\")\n",
    "print(f\"  Nombre d'√©chantillons : {metrics_train['n_samples']}\")\n",
    "print(f\"\\n  üìà M√©triques de performance :\")\n",
    "print(f\"  MSE (Mean Squared Error)      : {metrics_train['MSE']:.6f}\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): {metrics_train['RMSE']:.6f}\")\n",
    "print(f\"  MAE (Mean Absolute Error)     : {metrics_train['MAE']:.6f}\")\n",
    "print(f\"  R¬≤ (Coefficient de d√©terminat): {metrics_train['R2']:.6f}\")\n",
    "\n",
    "# Interpr√©tation du R¬≤\n",
    "if metrics_train[\"R2\"] >= 0.9:\n",
    "    interpretation = \"Excellent (>90% de variance expliqu√©e)\"\n",
    "elif metrics_train[\"R2\"] >= 0.7:\n",
    "    interpretation = \"Bon (70-90% de variance expliqu√©e)\"\n",
    "elif metrics_train[\"R2\"] >= 0.5:\n",
    "    interpretation = \"Mod√©r√© (50-70% de variance expliqu√©e)\"\n",
    "else:\n",
    "    interpretation = \"Faible (<50% de variance expliqu√©e)\"\n",
    "\n",
    "print(f\"\\n  üìù Interpr√©tation du R¬≤ : {interpretation}\")\n",
    "\n",
    "# Visualisation : Valeurs r√©elles vs pr√©dites\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train.values, y_train_pred, alpha=0.5, s=30)\n",
    "plt.plot(\n",
    "    [y_train.min(), y_train.max()],\n",
    "    [y_train.min(), y_train.max()],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Pr√©diction parfaite\",\n",
    ")\n",
    "plt.xlabel(\"Valeurs R√©elles\")\n",
    "plt.ylabel(\"Valeurs Pr√©dites\")\n",
    "plt.title(f\"R√©gression Lin√©aire - Train Set (R¬≤ = {metrics_train['R2']:.4f})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{BASE_DIR}/predictions_train_LR.png\", dpi=300)\n",
    "print(\"\\nüíæ Graphique pr√©dictions/r√©alit√© sauvegard√© (train)\")\n",
    "\n",
    "# Distribution des r√©sidus\n",
    "residuals_train = y_train.values - y_train_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
